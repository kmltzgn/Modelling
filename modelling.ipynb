{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0298007",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4e1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd1a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data = pd.read_csv('house_data_EDA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924ea488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 308 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLI  \\\n",
       "0          2003       196.0         706           0  ...               0   \n",
       "1          1976         0.0         978           0  ...               0   \n",
       "2          2002       162.0         486           0  ...               0   \n",
       "3          1970         0.0         216           0  ...               0   \n",
       "4          2000       350.0         655           0  ...               0   \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0               0             0             0            1   \n",
       "1               0             0             0            1   \n",
       "2               0             0             0            1   \n",
       "3               0             0             0            1   \n",
       "4               0             0             0            1   \n",
       "\n",
       "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                      0                     0                     0   \n",
       "1                      0                     0                     0   \n",
       "2                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "4                      0                     0                     0   \n",
       "\n",
       "   SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     1                      0  \n",
       "1                     1                      0  \n",
       "2                     1                      0  \n",
       "3                     0                      0  \n",
       "4                     1                      0  \n",
       "\n",
       "[5 rows x 308 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104814a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "house_data.SalePrice.hist(bins=30)\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of sale prices');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d421db3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "         ...  \n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3464ed14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "1455    False\n",
       "1456    False\n",
       "1457    False\n",
       "1458    False\n",
       "1459    False\n",
       "Name: SalePrice_isna, Length: 1460, dtype: bool>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data.SalePrice_isna.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570df77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = house_data['SalePrice']\n",
    "\n",
    "X = house_data.drop('SalePrice', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811f7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5db1bc",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b30e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e5ca283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a81934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9407060283217248"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As can be seen below, the linear model overfits the data in the train set\n",
    "\n",
    "linear_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ed018b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13915697192003418"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The score is pretty low when the model is applie top the test set\n",
    "\n",
    "linear_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe32b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 18805.90017233309\n",
      "Root Mean Squared Error: 81258.51855993982\n"
     ]
    }
   ],
   "source": [
    "# The standard error for train and test sets are computed below \n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train,linear_model.predict(X_train)))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test,linear_model.predict(X_test)))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a32c1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22265829 0.82160148 0.78891663 0.88467709 0.66450577]\n",
      "Average 5-Fold CV Score: 0.6764718527575286\n"
     ]
    }
   ],
   "source": [
    "# We also check that the cross-validation score is very low \n",
    "\n",
    "cv_scores_5 = cross_val_score(linear_model,X,y,cv=5)\n",
    "\n",
    "print(cv_scores_5)\n",
    "\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d11bb09",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "041d7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we apply the Ridge model to our dataframe. First, we select the grid of alpha values\n",
    "\n",
    "params_grid= {'alpha': 5*10**np.logspace(2,-2,200)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49c651c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1347977507.982727, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 807624501.9211426, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1761294003.262085, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1297138727.6903687, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2165587162.588867, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1312752954.2996216, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2434606339.220093, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1588765004.3374634, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2869919953.5750732, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1997694147.736206, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 597826836.4608154, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37491596139.02228, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24188964305.933533, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 737117697.4874878, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55575575040.53363, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38708386261.60034, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1072878956.1119385, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72594363190.57416, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50389521418.02661, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1260080297.4088135, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83809809022.88406, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50896684851.77579, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1451797402.0601196, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 98412707841.44449, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77518472495.56598, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1882278926.8518677, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 94722694193.0877, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86129135974.00992, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2161731492.0981445, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114262656105.38712, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85774159500.39166, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2518680206.251526, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 129370318869.65533, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91804807193.58755, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11168470524.481018, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 140894107778.55383, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106661133375.45682, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11349404606.405579, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 150886209345.16528, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 147397232156.9693, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4350236458.860779, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 158901391755.14713, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 181174549188.39856, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5011400369.746887, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163952747436.80066, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 166967084269.30774, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5706714523.71814, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170889595554.07397, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171324418262.00226, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6774194541.844421, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171583273542.21875, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 173660298531.00305, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45045990775.95456, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8103024091.1311035, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171665310175.78778, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 175896135579.70786, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9674305313.840454, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171714822531.82822, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 179430836205.70834, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13734320655.853882, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 174191126601.15048, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 179226064506.61743, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19272224803.280975, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 173343870656.9421, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 178920920850.11493, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69366308881.22571, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 172123169936.81107, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 178374954478.33212, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100246357297.37363, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171053513738.646, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 177791768546.50928, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116855224809.08676, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170257033772.23108, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 176939976861.068, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 116150331531.76526, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 169459175842.9322, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 175391962324.88055, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 121286991211.20999, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 168721423020.3397, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 177795779814.61823, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 134323166610.64018, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 167891140127.2538, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 172432427337.59946, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 144936636399.4184, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 167364693573.4543, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171503333650.70453, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 153751498051.80524, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 165895903998.9609, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170659882703.06424, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 160246769533.5159, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 165304686012.90506, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170172332272.95023, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 167287640551.9212, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164734733909.9181, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 169878041041.19147, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 172061036436.98883, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164188098376.7738, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 169982532299.40814, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 175314816543.2229, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163664089975.03757, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170995753509.85583, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 178137893935.88245, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163162707251.44736, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170514846171.57108, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 180241627777.3311, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162684837581.75342, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170346255516.7873, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182152517380.6528, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162233212761.95203, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170113792158.8297, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 183755434351.2712, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162466462530.01147, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35770996338.78943, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 169840915554.89157, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184906940839.80872, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161640187704.4702, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77219809517.52353, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 169624049841.34375, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186247568619.81107, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161027120715.0598, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96174862092.79909, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 169332443431.45236, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187202546846.36624, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 160646826930.9264, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 106989087769.38031, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 169016347219.18304, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187979731588.72968, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 160286937589.9992, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 114542392189.9476, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 168696376928.17963, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 188638156643.82825, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 159946229092.83267, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 120131627135.30412, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 168377937004.39963, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189199227794.2851, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 159623606970.47733, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 124436260294.76483, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 168043607450.03406, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 189679664233.0825, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 159318092844.82297, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 127863786371.07982, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 167749464500.50204, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190093147055.2677, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 159028622354.32742, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 130630577150.04483, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 167452163159.23624, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190451339092.05237, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 158753648026.63983, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 132873642970.24274, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 167154689047.3625, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190763086272.20923, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 158605206466.0508, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 134698845588.1041, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 166851199058.7311, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191034433481.97604, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 158349596906.9217, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 136361057036.6235, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 166537671870.05457, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191348900241.25537, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 158106934368.6437, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 137766054699.2168, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 166300961632.86395, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191632481952.7876, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 157876226705.47717, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 138837069639.8349, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 166050796923.46994, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191803073353.31787, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 157657332148.6731, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5654683063.169159, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 165803599614.5129, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 192023570157.06216, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 157448926212.46857, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7636807421.333954, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 165614529330.624, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 192224537708.1986, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 157251025479.30908, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8521495537.193634, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 165384493510.22327, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 192369760221.968, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 157062826850.01132, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20386342249.86682, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 165163995587.65234, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 192381207780.73535, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156883760829.2881, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34229347956.62805, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164957045488.566, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 192221210886.26797, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156713429928.29263, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40723246631.1485, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164773732417.60147, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191644458430.96042, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156551451914.5677, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46451911304.800964, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164603587558.76126, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191699969851.39606, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156397141868.45966, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51515879625.90799, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164396645007.14722, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191614740979.20425, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156250444362.5984, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56024656266.3457, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163935110705.35577, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191544549199.54968, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156114622687.9743, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60056526915.37561, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164243840381.3913, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191484920884.54102, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155988631926.4206, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63675760761.54689, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164085025107.4905, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191427054580.95944, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155868710372.46368, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66937992650.30675, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163934773038.84482, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191370580080.65558, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155754564295.45486, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69888957864.76146, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163791880735.8612, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191315867133.58688, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155645933678.25076, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72568016183.9506, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163656249206.66754, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191257487160.62955, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155542547426.29922, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75008016323.85428, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163527499213.4069, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191235317654.2032, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155444143332.19562, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77234891187.00443, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163405237839.6147, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191245959117.89594, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155350472327.79764, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79269648417.5923, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163289120264.85034, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191205987584.20297, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155261293853.44904, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81134796520.0187, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163178854729.44427, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191149801414.67847, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155176357479.28226, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82851078184.5362, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163074145894.54132, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191100518885.73273, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155095382760.5056, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84434643840.58038, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162974684838.3535, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191052992443.41644, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155018172300.98083, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85897231785.30705, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162880207599.23773, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 191007465793.71527, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154944812839.37695, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87249643316.39534, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162790429816.96375, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190964187263.4098, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154875275627.14255, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88502940152.5009, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162705115294.15955, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 758076477.3254395, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190922156083.69318, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154808537745.6451, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89663924108.44746, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162624035399.7653, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29693329329.44574, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190881308864.15802, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154744808655.0715, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 90746139854.33191, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162546968098.91034, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24097239874.474304, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190842469435.69037, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154684047149.45233, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91752900393.1821, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162473704996.02768, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18762733657.23831, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190805309192.19684, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154626112347.42178, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91349516683.77475, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162405006234.30704, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14561794164.740631, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190769662822.81992, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154570870338.38867, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92234035257.43999, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162344247657.8969, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8521817406.877136, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190735482416.11874, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154518193499.75345, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 93062050206.24127, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162286549114.17624, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3557506160.4645386, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190702694722.2232, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154467959566.18152, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 93820260092.16847, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162233570705.10974, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 655979817.2971191, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190671263986.35587, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154420052639.1083, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 93994044170.11337, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162182508196.38156, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190641115331.36374, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154374362267.68896, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 94686388144.647, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162135088755.8711, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190607144440.89838, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154330784553.5136, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95336605402.86356, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162081569713.4307, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190579709398.053, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154289218629.12164, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95948393851.81871, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162042397886.08014, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190553407914.34598, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154249571390.51416, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96524650232.49344, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162005619648.30145, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190528196203.55286, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154211752744.53116, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97067518930.07324, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161970906089.6933, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15098191485.664429, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190504054808.92163, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154175677165.86026, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97579222895.82256, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161938065857.19562, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20188672316.83017, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190480918961.809, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154141262911.06433, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 98062645351.70184, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161906663489.2859, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25073735039.014587, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190458768064.33035, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154108431615.9461, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 98521965402.94397, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161876244781.27826, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24188378683.775574, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190437555474.65955, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154077109218.7315, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 98958107374.93756, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161846063698.30005, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26420809967.73831, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190417237802.81546, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154047173845.04425, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 99371618476.79942, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161815178623.85577, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29284679325.069427, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190397794252.57977, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154018568632.57816, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 99763699067.96696, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161781990497.9112, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32222368020.232513, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190379187493.78613, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 153991272771.714, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100135722646.86002, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161743448390.3791, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35094446768.351776, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190361376343.46902, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 153965226595.33066, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100487889998.85516, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161691852272.61215, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37837461070.70593, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190344335345.859, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 153940377742.52676, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100821142786.44284, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161604137116.82123, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40426632949.28079, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190328033872.88297, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 153916666915.24136, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101138177626.65619, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161567239421.52423, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42865808297.2836, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190312440574.76602, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 153894041146.68268, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101441315551.54712, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161540237883.16748, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45158618704.23276, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 190297529656.9626, tolerance: 537415025.1745834\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 153872450221.62634, tolerance: 572016182.2224234\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101730996192.2631, tolerance: 525605188.80204767\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161518225254.52826, tolerance: 571614666.2949618\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/KML/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47311207256.81967, tolerance: 579592113.9945964\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(random_state=42),\n",
       "             param_grid={'alpha': array([5.00000000e+100, 1.50013777e+096, 7.20863443e+091, 5.43104773e+087,\n",
       "       6.28621887e+083, 1.09631830e+080, 2.82795564e+076, 1.06000758e+073,\n",
       "       5.67682107e+069, 4.27417911e+066, 4.45512513e+063, 6.33487172e+060,\n",
       "       1.21167595e+058, 3.07596791e+055, 1.02320602e+053, 4.40576332e+050,\n",
       "       2.42709615e+048,...\n",
       "       5.28523181e+000, 5.27198669e+000, 5.25937161e+000, 5.24735526e+000,\n",
       "       5.23590801e+000, 5.22500181e+000, 5.21461007e+000, 5.20470763e+000,\n",
       "       5.19527060e+000, 5.18627637e+000, 5.17770345e+000, 5.16953151e+000,\n",
       "       5.16174120e+000, 5.15431419e+000, 5.14723307e+000, 5.14048129e+000,\n",
       "       5.13404315e+000, 5.12790372e+000, 5.12204882e+000, 5.11646496e+000])},\n",
       "             return_train_score=True, scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform GridSearchCV to find optimal value of alpha\n",
    "\n",
    "lasso= Lasso(random_state= 42)\n",
    "grid_lasso= GridSearchCV(estimator= lasso, \n",
    "                        param_grid= params_grid,\n",
    "                        cv= 5,\n",
    "                        scoring= 'r2',\n",
    "                        return_train_score= True,\n",
    "                        verbose= 1)      \n",
    "grid_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00049e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=368.8787209631105, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best estimation for alpha\n",
    "\n",
    "grid_lasso.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61484acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8038082809692184"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best score\n",
    "\n",
    "grid_lasso.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89ebdf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.029847</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>452.23935</td>\n",
       "      <td>{'alpha': 452.23934959238204}</td>\n",
       "      <td>0.809144</td>\n",
       "      <td>0.777026</td>\n",
       "      <td>0.618781</td>\n",
       "      <td>0.893938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798173</td>\n",
       "      <td>0.100716</td>\n",
       "      <td>3</td>\n",
       "      <td>0.859033</td>\n",
       "      <td>0.866620</td>\n",
       "      <td>0.886711</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.849205</td>\n",
       "      <td>0.862695</td>\n",
       "      <td>0.013446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.030779</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>368.878721</td>\n",
       "      <td>{'alpha': 368.8787209631105}</td>\n",
       "      <td>0.815677</td>\n",
       "      <td>0.785461</td>\n",
       "      <td>0.630947</td>\n",
       "      <td>0.893071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803808</td>\n",
       "      <td>0.096375</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866372</td>\n",
       "      <td>0.873871</td>\n",
       "      <td>0.895190</td>\n",
       "      <td>0.859853</td>\n",
       "      <td>0.859383</td>\n",
       "      <td>0.870934</td>\n",
       "      <td>0.013221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.032175</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>303.669295</td>\n",
       "      <td>{'alpha': 303.6692950499845}</td>\n",
       "      <td>0.820051</td>\n",
       "      <td>0.789011</td>\n",
       "      <td>0.635896</td>\n",
       "      <td>0.890952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802504</td>\n",
       "      <td>0.091173</td>\n",
       "      <td>2</td>\n",
       "      <td>0.871732</td>\n",
       "      <td>0.884482</td>\n",
       "      <td>0.903413</td>\n",
       "      <td>0.867318</td>\n",
       "      <td>0.874728</td>\n",
       "      <td>0.880335</td>\n",
       "      <td>0.012843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.034262</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>252.196571</td>\n",
       "      <td>{'alpha': 252.19657052712662}</td>\n",
       "      <td>0.824065</td>\n",
       "      <td>0.789903</td>\n",
       "      <td>0.639614</td>\n",
       "      <td>0.888137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798028</td>\n",
       "      <td>0.085438</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876780</td>\n",
       "      <td>0.892239</td>\n",
       "      <td>0.909138</td>\n",
       "      <td>0.880251</td>\n",
       "      <td>0.888766</td>\n",
       "      <td>0.889435</td>\n",
       "      <td>0.011323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.031929</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>211.215444</td>\n",
       "      <td>{'alpha': 211.21544414353718}</td>\n",
       "      <td>0.827646</td>\n",
       "      <td>0.790034</td>\n",
       "      <td>0.641592</td>\n",
       "      <td>0.881233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791440</td>\n",
       "      <td>0.080583</td>\n",
       "      <td>5</td>\n",
       "      <td>0.881838</td>\n",
       "      <td>0.898010</td>\n",
       "      <td>0.913172</td>\n",
       "      <td>0.889846</td>\n",
       "      <td>0.898370</td>\n",
       "      <td>0.896247</td>\n",
       "      <td>0.010418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.166749</td>\n",
       "      <td>0.019754</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>5.140481</td>\n",
       "      <td>{'alpha': 5.140481289681232}</td>\n",
       "      <td>0.863334</td>\n",
       "      <td>0.732280</td>\n",
       "      <td>0.699720</td>\n",
       "      <td>0.756416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722602</td>\n",
       "      <td>0.097568</td>\n",
       "      <td>122</td>\n",
       "      <td>0.935982</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.940210</td>\n",
       "      <td>0.952032</td>\n",
       "      <td>0.940044</td>\n",
       "      <td>0.944426</td>\n",
       "      <td>0.007144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.161456</td>\n",
       "      <td>0.015660</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>5.134043</td>\n",
       "      <td>{'alpha': 5.134043148582803}</td>\n",
       "      <td>0.863331</td>\n",
       "      <td>0.732215</td>\n",
       "      <td>0.699741</td>\n",
       "      <td>0.756380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722588</td>\n",
       "      <td>0.097558</td>\n",
       "      <td>123</td>\n",
       "      <td>0.935985</td>\n",
       "      <td>0.953864</td>\n",
       "      <td>0.940211</td>\n",
       "      <td>0.952033</td>\n",
       "      <td>0.940047</td>\n",
       "      <td>0.944428</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.161407</td>\n",
       "      <td>0.016580</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>5.127904</td>\n",
       "      <td>{'alpha': 5.127903718961786}</td>\n",
       "      <td>0.863328</td>\n",
       "      <td>0.732153</td>\n",
       "      <td>0.699761</td>\n",
       "      <td>0.756342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722574</td>\n",
       "      <td>0.097548</td>\n",
       "      <td>124</td>\n",
       "      <td>0.935989</td>\n",
       "      <td>0.953867</td>\n",
       "      <td>0.940213</td>\n",
       "      <td>0.952033</td>\n",
       "      <td>0.940050</td>\n",
       "      <td>0.944431</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.156927</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>5.122049</td>\n",
       "      <td>{'alpha': 5.1220488171005565}</td>\n",
       "      <td>0.863325</td>\n",
       "      <td>0.732093</td>\n",
       "      <td>0.699781</td>\n",
       "      <td>0.756301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722560</td>\n",
       "      <td>0.097538</td>\n",
       "      <td>125</td>\n",
       "      <td>0.935992</td>\n",
       "      <td>0.953870</td>\n",
       "      <td>0.940214</td>\n",
       "      <td>0.952033</td>\n",
       "      <td>0.940053</td>\n",
       "      <td>0.944433</td>\n",
       "      <td>0.007142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.160429</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>5.116465</td>\n",
       "      <td>{'alpha': 5.1164649614037705}</td>\n",
       "      <td>0.863323</td>\n",
       "      <td>0.732037</td>\n",
       "      <td>0.699799</td>\n",
       "      <td>0.756269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722547</td>\n",
       "      <td>0.097530</td>\n",
       "      <td>126</td>\n",
       "      <td>0.935996</td>\n",
       "      <td>0.953873</td>\n",
       "      <td>0.940215</td>\n",
       "      <td>0.952034</td>\n",
       "      <td>0.940056</td>\n",
       "      <td>0.944435</td>\n",
       "      <td>0.007142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "85        0.029847      0.006826         0.005152        0.000672   452.23935   \n",
       "86        0.030779      0.006523         0.005592        0.001611  368.878721   \n",
       "87        0.032175      0.004601         0.005141        0.000420  303.669295   \n",
       "88        0.034262      0.002452         0.006008        0.002055  252.196571   \n",
       "89        0.031929      0.002686         0.005640        0.000883  211.215444   \n",
       "..             ...           ...              ...             ...         ...   \n",
       "195       0.166749      0.019754         0.005083        0.000133    5.140481   \n",
       "196       0.161456      0.015660         0.005085        0.000078    5.134043   \n",
       "197       0.161407      0.016580         0.005114        0.000107    5.127904   \n",
       "198       0.156927      0.018267         0.005160        0.000129    5.122049   \n",
       "199       0.160429      0.013482         0.005144        0.000148    5.116465   \n",
       "\n",
       "                            params  split0_test_score  split1_test_score  \\\n",
       "85   {'alpha': 452.23934959238204}           0.809144           0.777026   \n",
       "86    {'alpha': 368.8787209631105}           0.815677           0.785461   \n",
       "87    {'alpha': 303.6692950499845}           0.820051           0.789011   \n",
       "88   {'alpha': 252.19657052712662}           0.824065           0.789903   \n",
       "89   {'alpha': 211.21544414353718}           0.827646           0.790034   \n",
       "..                             ...                ...                ...   \n",
       "195   {'alpha': 5.140481289681232}           0.863334           0.732280   \n",
       "196   {'alpha': 5.134043148582803}           0.863331           0.732215   \n",
       "197   {'alpha': 5.127903718961786}           0.863328           0.732153   \n",
       "198  {'alpha': 5.1220488171005565}           0.863325           0.732093   \n",
       "199  {'alpha': 5.1164649614037705}           0.863323           0.732037   \n",
       "\n",
       "     split2_test_score  split3_test_score  ...  mean_test_score  \\\n",
       "85            0.618781           0.893938  ...         0.798173   \n",
       "86            0.630947           0.893071  ...         0.803808   \n",
       "87            0.635896           0.890952  ...         0.802504   \n",
       "88            0.639614           0.888137  ...         0.798028   \n",
       "89            0.641592           0.881233  ...         0.791440   \n",
       "..                 ...                ...  ...              ...   \n",
       "195           0.699720           0.756416  ...         0.722602   \n",
       "196           0.699741           0.756380  ...         0.722588   \n",
       "197           0.699761           0.756342  ...         0.722574   \n",
       "198           0.699781           0.756301  ...         0.722560   \n",
       "199           0.699799           0.756269  ...         0.722547   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "85         0.100716                3            0.859033            0.866620   \n",
       "86         0.096375                1            0.866372            0.873871   \n",
       "87         0.091173                2            0.871732            0.884482   \n",
       "88         0.085438                4            0.876780            0.892239   \n",
       "89         0.080583                5            0.881838            0.898010   \n",
       "..              ...              ...                 ...                 ...   \n",
       "195        0.097568              122            0.935982            0.953861   \n",
       "196        0.097558              123            0.935985            0.953864   \n",
       "197        0.097548              124            0.935989            0.953867   \n",
       "198        0.097538              125            0.935992            0.953870   \n",
       "199        0.097530              126            0.935996            0.953873   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "85             0.886711            0.851907            0.849205   \n",
       "86             0.895190            0.859853            0.859383   \n",
       "87             0.903413            0.867318            0.874728   \n",
       "88             0.909138            0.880251            0.888766   \n",
       "89             0.913172            0.889846            0.898370   \n",
       "..                  ...                 ...                 ...   \n",
       "195            0.940210            0.952032            0.940044   \n",
       "196            0.940211            0.952033            0.940047   \n",
       "197            0.940213            0.952033            0.940050   \n",
       "198            0.940214            0.952033            0.940053   \n",
       "199            0.940215            0.952034            0.940056   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "85           0.862695         0.013446  \n",
       "86           0.870934         0.013221  \n",
       "87           0.880335         0.012843  \n",
       "88           0.889435         0.011323  \n",
       "89           0.896247         0.010418  \n",
       "..                ...              ...  \n",
       "195          0.944426         0.007144  \n",
       "196          0.944428         0.007143  \n",
       "197          0.944431         0.007143  \n",
       "198          0.944433         0.007142  \n",
       "199          0.944435         0.007142  \n",
       "\n",
       "[115 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_lasso.cv_results_)\n",
    "cv_results = cv_results[cv_results['param_alpha']<=500]\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b1e480e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Score')\n",
    "plt.title(\"Model score with respect to alpha \")\n",
    "plt.legend(['train score', 'test score'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32cf572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Lasso(alpha=358.29145728643215, random_state=42)\n",
      "0.803863618717268\n"
     ]
    }
   ],
   "source": [
    "# It seems like the score function seems to be a smooth function with respect to the alpha hyperparameter. \n",
    "# Let us get closer to the global max score by varying the alpha around the value that we found above\n",
    "\n",
    "\n",
    "params_grid_max= {'alpha': np.linspace(350,380,200)}\n",
    "\n",
    "grid_lasso_max= GridSearchCV(estimator= lasso, \n",
    "                        param_grid= params_grid_max,\n",
    "                        cv= 5,\n",
    "                        scoring= 'r2',\n",
    "                        return_train_score= True,\n",
    "                        verbose= 1)      \n",
    "grid_lasso_max.fit(X_train, y_train)\n",
    "\n",
    "print(grid_lasso_max.best_estimator_)\n",
    "print(grid_lasso_max.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ecfb589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 28493.64424798187\n",
      "Root Mean Squared Error: 31669.2434490048\n"
     ]
    }
   ],
   "source": [
    "# Last we print the values of standard error \n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train,grid_lasso_max.predict(X_train)))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test,grid_lasso_max.predict(X_test)))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5368e",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "825abf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we apply the Ridge model to our dataframe. First, we select the grid of alpha values\n",
    "\n",
    "params_grid= {'alpha': 4*5**np.logspace(2,-2,100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "586ece11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(random_state=42),\n",
       "             param_grid={'alpha': array([3.15544362e+70, 1.94806548e+64, 4.28329229e+58, 2.99624640e+53,\n",
       "       6.01659968e+48, 3.15800894e+44, 3.97826279e+40, 1.11279188e+37,\n",
       "       6.43869699e+33, 7.22441866e+30, 1.48209914e+28, 5.26913727e+25,\n",
       "       3.09155101e+23, 2.86324978e+21, 4.01953995e+19, 8.24291277e+17,\n",
       "       2.38754092e+16, 9.47249015e+14, 5....\n",
       "       4.39540411e+00, 4.35874958e+00, 4.32561754e+00, 4.29564820e+00,\n",
       "       4.26852207e+00, 4.24395492e+00, 4.22169339e+00, 4.20151120e+00,\n",
       "       4.18320595e+00, 4.16659635e+00, 4.15151972e+00, 4.13782996e+00,\n",
       "       4.12539567e+00, 4.11409855e+00, 4.10383197e+00, 4.09449975e+00,\n",
       "       4.08601506e+00, 4.07829944e+00, 4.07128194e+00, 4.06489837e+00])},\n",
       "             return_train_score=True, scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform GridSearchCV to find optimal value of alpha\n",
    "\n",
    "ridge= Ridge(random_state= 42)\n",
    "grid_ridge= GridSearchCV(estimator= ridge, \n",
    "                        param_grid= params_grid,\n",
    "                        cv= 5,\n",
    "                        scoring= 'r2',\n",
    "                        return_train_score= True,\n",
    "                        verbose= 1)      \n",
    "grid_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f252c736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=11.53282176451345, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best estimation for alpha\n",
    "\n",
    "grid_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7aba37ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109664423400019"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best score\n",
    "\n",
    "grid_ridge.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4392540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.017279</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>76.153722</td>\n",
       "      <td>{'alpha': 76.15372213775619}</td>\n",
       "      <td>0.813546</td>\n",
       "      <td>0.774176</td>\n",
       "      <td>0.619143</td>\n",
       "      <td>0.892927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799416</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>57</td>\n",
       "      <td>0.863607</td>\n",
       "      <td>0.873146</td>\n",
       "      <td>0.896373</td>\n",
       "      <td>0.854380</td>\n",
       "      <td>0.853782</td>\n",
       "      <td>0.868258</td>\n",
       "      <td>0.015736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.017092</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>58.615467</td>\n",
       "      <td>{'alpha': 58.61546721719499}</td>\n",
       "      <td>0.816721</td>\n",
       "      <td>0.777533</td>\n",
       "      <td>0.625413</td>\n",
       "      <td>0.892498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802250</td>\n",
       "      <td>0.099612</td>\n",
       "      <td>56</td>\n",
       "      <td>0.869307</td>\n",
       "      <td>0.878476</td>\n",
       "      <td>0.900178</td>\n",
       "      <td>0.860653</td>\n",
       "      <td>0.859520</td>\n",
       "      <td>0.873627</td>\n",
       "      <td>0.014930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.017417</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>46.177695</td>\n",
       "      <td>{'alpha': 46.177694642348854}</td>\n",
       "      <td>0.819333</td>\n",
       "      <td>0.780149</td>\n",
       "      <td>0.630973</td>\n",
       "      <td>0.891648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.097715</td>\n",
       "      <td>55</td>\n",
       "      <td>0.874259</td>\n",
       "      <td>0.883120</td>\n",
       "      <td>0.903542</td>\n",
       "      <td>0.866153</td>\n",
       "      <td>0.864521</td>\n",
       "      <td>0.878319</td>\n",
       "      <td>0.014242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.017440</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>37.158145</td>\n",
       "      <td>{'alpha': 37.158144933965566}</td>\n",
       "      <td>0.821452</td>\n",
       "      <td>0.782151</td>\n",
       "      <td>0.635860</td>\n",
       "      <td>0.890484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806325</td>\n",
       "      <td>0.095965</td>\n",
       "      <td>54</td>\n",
       "      <td>0.878533</td>\n",
       "      <td>0.887142</td>\n",
       "      <td>0.906501</td>\n",
       "      <td>0.870951</td>\n",
       "      <td>0.868866</td>\n",
       "      <td>0.882399</td>\n",
       "      <td>0.013657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.017602</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>30.483168</td>\n",
       "      <td>{'alpha': 30.483168194087035}</td>\n",
       "      <td>0.823155</td>\n",
       "      <td>0.783654</td>\n",
       "      <td>0.640122</td>\n",
       "      <td>0.889098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807720</td>\n",
       "      <td>0.094367</td>\n",
       "      <td>53</td>\n",
       "      <td>0.882209</td>\n",
       "      <td>0.890617</td>\n",
       "      <td>0.909094</td>\n",
       "      <td>0.875126</td>\n",
       "      <td>0.872638</td>\n",
       "      <td>0.885937</td>\n",
       "      <td>0.013159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.017218</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>25.451046</td>\n",
       "      <td>{'alpha': 25.451046439053968}</td>\n",
       "      <td>0.824517</td>\n",
       "      <td>0.784756</td>\n",
       "      <td>0.643814</td>\n",
       "      <td>0.887570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808778</td>\n",
       "      <td>0.092917</td>\n",
       "      <td>29</td>\n",
       "      <td>0.885366</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.911360</td>\n",
       "      <td>0.878756</td>\n",
       "      <td>0.875915</td>\n",
       "      <td>0.889003</td>\n",
       "      <td>0.012733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.017627</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>21.59295</td>\n",
       "      <td>{'alpha': 21.592949974044902}</td>\n",
       "      <td>0.825606</td>\n",
       "      <td>0.785544</td>\n",
       "      <td>0.646996</td>\n",
       "      <td>0.885966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809563</td>\n",
       "      <td>0.091610</td>\n",
       "      <td>19</td>\n",
       "      <td>0.888077</td>\n",
       "      <td>0.896213</td>\n",
       "      <td>0.913338</td>\n",
       "      <td>0.881914</td>\n",
       "      <td>0.878768</td>\n",
       "      <td>0.891662</td>\n",
       "      <td>0.012367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>18.589201</td>\n",
       "      <td>{'alpha': 18.58920129397054}</td>\n",
       "      <td>0.826480</td>\n",
       "      <td>0.786086</td>\n",
       "      <td>0.649728</td>\n",
       "      <td>0.884337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.090436</td>\n",
       "      <td>13</td>\n",
       "      <td>0.890410</td>\n",
       "      <td>0.898464</td>\n",
       "      <td>0.915065</td>\n",
       "      <td>0.884667</td>\n",
       "      <td>0.881259</td>\n",
       "      <td>0.893973</td>\n",
       "      <td>0.012050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>16.21767</td>\n",
       "      <td>{'alpha': 16.217669865086737}</td>\n",
       "      <td>0.827185</td>\n",
       "      <td>0.786436</td>\n",
       "      <td>0.652067</td>\n",
       "      <td>0.882721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810515</td>\n",
       "      <td>0.089384</td>\n",
       "      <td>9</td>\n",
       "      <td>0.892423</td>\n",
       "      <td>0.900423</td>\n",
       "      <td>0.916574</td>\n",
       "      <td>0.887073</td>\n",
       "      <td>0.883441</td>\n",
       "      <td>0.895987</td>\n",
       "      <td>0.011773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>14.321278</td>\n",
       "      <td>{'alpha': 14.321277703921314}</td>\n",
       "      <td>0.827760</td>\n",
       "      <td>0.786638</td>\n",
       "      <td>0.654067</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810765</td>\n",
       "      <td>0.088443</td>\n",
       "      <td>6</td>\n",
       "      <td>0.894164</td>\n",
       "      <td>0.902136</td>\n",
       "      <td>0.917896</td>\n",
       "      <td>0.889182</td>\n",
       "      <td>0.885360</td>\n",
       "      <td>0.897748</td>\n",
       "      <td>0.011532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>12.787124</td>\n",
       "      <td>{'alpha': 12.78712416946227}</td>\n",
       "      <td>0.828235</td>\n",
       "      <td>0.786726</td>\n",
       "      <td>0.655775</td>\n",
       "      <td>0.879636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810907</td>\n",
       "      <td>0.087602</td>\n",
       "      <td>4</td>\n",
       "      <td>0.895676</td>\n",
       "      <td>0.903639</td>\n",
       "      <td>0.919056</td>\n",
       "      <td>0.891036</td>\n",
       "      <td>0.887052</td>\n",
       "      <td>0.899292</td>\n",
       "      <td>0.011319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.018189</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>11.532822</td>\n",
       "      <td>{'alpha': 11.53282176451345}</td>\n",
       "      <td>0.828632</td>\n",
       "      <td>0.786729</td>\n",
       "      <td>0.657233</td>\n",
       "      <td>0.878200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810966</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896993</td>\n",
       "      <td>0.904962</td>\n",
       "      <td>0.920076</td>\n",
       "      <td>0.892672</td>\n",
       "      <td>0.888549</td>\n",
       "      <td>0.900651</td>\n",
       "      <td>0.011130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.017579</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>10.497394</td>\n",
       "      <td>{'alpha': 10.49739405886303}</td>\n",
       "      <td>0.828968</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.658478</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810964</td>\n",
       "      <td>0.086182</td>\n",
       "      <td>2</td>\n",
       "      <td>0.898145</td>\n",
       "      <td>0.906132</td>\n",
       "      <td>0.920976</td>\n",
       "      <td>0.894119</td>\n",
       "      <td>0.889879</td>\n",
       "      <td>0.901850</td>\n",
       "      <td>0.010963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.017541</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>9.635112</td>\n",
       "      <td>{'alpha': 9.635112378383278}</td>\n",
       "      <td>0.829257</td>\n",
       "      <td>0.786559</td>\n",
       "      <td>0.659542</td>\n",
       "      <td>0.875579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810915</td>\n",
       "      <td>0.085583</td>\n",
       "      <td>3</td>\n",
       "      <td>0.899157</td>\n",
       "      <td>0.907169</td>\n",
       "      <td>0.921772</td>\n",
       "      <td>0.895404</td>\n",
       "      <td>0.891064</td>\n",
       "      <td>0.902913</td>\n",
       "      <td>0.010814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.017654</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>8.911258</td>\n",
       "      <td>{'alpha': 8.911257834966829}</td>\n",
       "      <td>0.829509</td>\n",
       "      <td>0.786416</td>\n",
       "      <td>0.660453</td>\n",
       "      <td>0.874398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810833</td>\n",
       "      <td>0.085048</td>\n",
       "      <td>5</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>0.908092</td>\n",
       "      <td>0.922478</td>\n",
       "      <td>0.896547</td>\n",
       "      <td>0.892121</td>\n",
       "      <td>0.903857</td>\n",
       "      <td>0.010680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.017363</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>8.299165</td>\n",
       "      <td>{'alpha': 8.299164947833209}</td>\n",
       "      <td>0.829730</td>\n",
       "      <td>0.786251</td>\n",
       "      <td>0.661233</td>\n",
       "      <td>0.873303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810727</td>\n",
       "      <td>0.084570</td>\n",
       "      <td>7</td>\n",
       "      <td>0.900834</td>\n",
       "      <td>0.908916</td>\n",
       "      <td>0.923105</td>\n",
       "      <td>0.897568</td>\n",
       "      <td>0.893068</td>\n",
       "      <td>0.904698</td>\n",
       "      <td>0.010561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.017249</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>7.778131</td>\n",
       "      <td>{'alpha': 7.77813118894308}</td>\n",
       "      <td>0.829927</td>\n",
       "      <td>0.786072</td>\n",
       "      <td>0.661903</td>\n",
       "      <td>0.872290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.084142</td>\n",
       "      <td>8</td>\n",
       "      <td>0.901532</td>\n",
       "      <td>0.909652</td>\n",
       "      <td>0.923664</td>\n",
       "      <td>0.898481</td>\n",
       "      <td>0.893918</td>\n",
       "      <td>0.905449</td>\n",
       "      <td>0.010453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>7.33192</td>\n",
       "      <td>{'alpha': 7.331919888627737}</td>\n",
       "      <td>0.830104</td>\n",
       "      <td>0.785884</td>\n",
       "      <td>0.662479</td>\n",
       "      <td>0.871356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810475</td>\n",
       "      <td>0.083759</td>\n",
       "      <td>10</td>\n",
       "      <td>0.902151</td>\n",
       "      <td>0.910312</td>\n",
       "      <td>0.924162</td>\n",
       "      <td>0.899300</td>\n",
       "      <td>0.894682</td>\n",
       "      <td>0.906122</td>\n",
       "      <td>0.010356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.017582</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>6.947675</td>\n",
       "      <td>{'alpha': 6.94767515680434}</td>\n",
       "      <td>0.830264</td>\n",
       "      <td>0.785694</td>\n",
       "      <td>0.662975</td>\n",
       "      <td>0.870497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810339</td>\n",
       "      <td>0.083415</td>\n",
       "      <td>11</td>\n",
       "      <td>0.902703</td>\n",
       "      <td>0.910905</td>\n",
       "      <td>0.924608</td>\n",
       "      <td>0.900036</td>\n",
       "      <td>0.895370</td>\n",
       "      <td>0.906724</td>\n",
       "      <td>0.010268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>6.615126</td>\n",
       "      <td>{'alpha': 6.61512649821009}</td>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.785505</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>0.869708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810202</td>\n",
       "      <td>0.083106</td>\n",
       "      <td>12</td>\n",
       "      <td>0.903196</td>\n",
       "      <td>0.911438</td>\n",
       "      <td>0.925007</td>\n",
       "      <td>0.900698</td>\n",
       "      <td>0.895991</td>\n",
       "      <td>0.907266</td>\n",
       "      <td>0.010188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.017398</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>6.326</td>\n",
       "      <td>{'alpha': 6.325999535037175}</td>\n",
       "      <td>0.830542</td>\n",
       "      <td>0.785319</td>\n",
       "      <td>0.663775</td>\n",
       "      <td>0.868983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810066</td>\n",
       "      <td>0.082829</td>\n",
       "      <td>14</td>\n",
       "      <td>0.903637</td>\n",
       "      <td>0.911919</td>\n",
       "      <td>0.925365</td>\n",
       "      <td>0.901295</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.907753</td>\n",
       "      <td>0.010116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.017174</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>6.073575</td>\n",
       "      <td>{'alpha': 6.0735750137322295}</td>\n",
       "      <td>0.830664</td>\n",
       "      <td>0.785139</td>\n",
       "      <td>0.664098</td>\n",
       "      <td>0.868320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809934</td>\n",
       "      <td>0.082579</td>\n",
       "      <td>15</td>\n",
       "      <td>0.904032</td>\n",
       "      <td>0.912353</td>\n",
       "      <td>0.925687</td>\n",
       "      <td>0.901833</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.908193</td>\n",
       "      <td>0.010051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.017528</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>5.852356</td>\n",
       "      <td>{'alpha': 5.852355627412319}</td>\n",
       "      <td>0.830776</td>\n",
       "      <td>0.784966</td>\n",
       "      <td>0.664379</td>\n",
       "      <td>0.867712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809806</td>\n",
       "      <td>0.082354</td>\n",
       "      <td>16</td>\n",
       "      <td>0.904387</td>\n",
       "      <td>0.912744</td>\n",
       "      <td>0.925976</td>\n",
       "      <td>0.902320</td>\n",
       "      <td>0.897518</td>\n",
       "      <td>0.908589</td>\n",
       "      <td>0.009991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>5.657812</td>\n",
       "      <td>{'alpha': 5.657812017433985}</td>\n",
       "      <td>0.830879</td>\n",
       "      <td>0.784801</td>\n",
       "      <td>0.664623</td>\n",
       "      <td>0.867156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809683</td>\n",
       "      <td>0.082152</td>\n",
       "      <td>17</td>\n",
       "      <td>0.904706</td>\n",
       "      <td>0.913099</td>\n",
       "      <td>0.926237</td>\n",
       "      <td>0.902760</td>\n",
       "      <td>0.897934</td>\n",
       "      <td>0.908947</td>\n",
       "      <td>0.009937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.017573</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>5.486187</td>\n",
       "      <td>{'alpha': 5.4861874773066}</td>\n",
       "      <td>0.830974</td>\n",
       "      <td>0.784644</td>\n",
       "      <td>0.664838</td>\n",
       "      <td>0.866648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809567</td>\n",
       "      <td>0.081969</td>\n",
       "      <td>18</td>\n",
       "      <td>0.904993</td>\n",
       "      <td>0.913419</td>\n",
       "      <td>0.926472</td>\n",
       "      <td>0.903159</td>\n",
       "      <td>0.898311</td>\n",
       "      <td>0.909271</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.017609</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>5.334347</td>\n",
       "      <td>{'alpha': 5.334346570692043}</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>0.784497</td>\n",
       "      <td>0.665026</td>\n",
       "      <td>0.866184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809456</td>\n",
       "      <td>0.081804</td>\n",
       "      <td>20</td>\n",
       "      <td>0.905252</td>\n",
       "      <td>0.913710</td>\n",
       "      <td>0.926684</td>\n",
       "      <td>0.903520</td>\n",
       "      <td>0.898653</td>\n",
       "      <td>0.909564</td>\n",
       "      <td>0.009843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.017154</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>5.199657</td>\n",
       "      <td>{'alpha': 5.199656882240699}</td>\n",
       "      <td>0.831142</td>\n",
       "      <td>0.784359</td>\n",
       "      <td>0.665191</td>\n",
       "      <td>0.865760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809353</td>\n",
       "      <td>0.081655</td>\n",
       "      <td>21</td>\n",
       "      <td>0.905486</td>\n",
       "      <td>0.913973</td>\n",
       "      <td>0.926875</td>\n",
       "      <td>0.903847</td>\n",
       "      <td>0.898963</td>\n",
       "      <td>0.909829</td>\n",
       "      <td>0.009803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.017306</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>5.079896</td>\n",
       "      <td>{'alpha': 5.079895970452175}</td>\n",
       "      <td>0.831217</td>\n",
       "      <td>0.784230</td>\n",
       "      <td>0.665336</td>\n",
       "      <td>0.865373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809256</td>\n",
       "      <td>0.081520</td>\n",
       "      <td>22</td>\n",
       "      <td>0.905697</td>\n",
       "      <td>0.914212</td>\n",
       "      <td>0.927049</td>\n",
       "      <td>0.904144</td>\n",
       "      <td>0.899246</td>\n",
       "      <td>0.910069</td>\n",
       "      <td>0.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.018009</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>4.973178</td>\n",
       "      <td>{'alpha': 4.973177638541748}</td>\n",
       "      <td>0.831285</td>\n",
       "      <td>0.784109</td>\n",
       "      <td>0.665465</td>\n",
       "      <td>0.865019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809165</td>\n",
       "      <td>0.081398</td>\n",
       "      <td>23</td>\n",
       "      <td>0.905888</td>\n",
       "      <td>0.914428</td>\n",
       "      <td>0.927205</td>\n",
       "      <td>0.904414</td>\n",
       "      <td>0.899502</td>\n",
       "      <td>0.910287</td>\n",
       "      <td>0.009732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.018240</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>4.877893</td>\n",
       "      <td>{'alpha': 4.877893122210622}</td>\n",
       "      <td>0.831349</td>\n",
       "      <td>0.783997</td>\n",
       "      <td>0.665578</td>\n",
       "      <td>0.864697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809081</td>\n",
       "      <td>0.081287</td>\n",
       "      <td>24</td>\n",
       "      <td>0.906061</td>\n",
       "      <td>0.914625</td>\n",
       "      <td>0.927347</td>\n",
       "      <td>0.904659</td>\n",
       "      <td>0.899735</td>\n",
       "      <td>0.910485</td>\n",
       "      <td>0.009701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.017395</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>4.792664</td>\n",
       "      <td>{'alpha': 4.792663876801774}</td>\n",
       "      <td>0.831407</td>\n",
       "      <td>0.783893</td>\n",
       "      <td>0.665679</td>\n",
       "      <td>0.864403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809003</td>\n",
       "      <td>0.081187</td>\n",
       "      <td>25</td>\n",
       "      <td>0.906217</td>\n",
       "      <td>0.914804</td>\n",
       "      <td>0.927475</td>\n",
       "      <td>0.904881</td>\n",
       "      <td>0.899947</td>\n",
       "      <td>0.910665</td>\n",
       "      <td>0.009673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.018663</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>4.716303</td>\n",
       "      <td>{'alpha': 4.71630344457983}</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.783797</td>\n",
       "      <td>0.665769</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808930</td>\n",
       "      <td>0.081096</td>\n",
       "      <td>26</td>\n",
       "      <td>0.906359</td>\n",
       "      <td>0.914966</td>\n",
       "      <td>0.927591</td>\n",
       "      <td>0.905083</td>\n",
       "      <td>0.900139</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.009647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.018114</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>4.647786</td>\n",
       "      <td>{'alpha': 4.647786475524222}</td>\n",
       "      <td>0.831510</td>\n",
       "      <td>0.783708</td>\n",
       "      <td>0.665848</td>\n",
       "      <td>0.863890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808863</td>\n",
       "      <td>0.081014</td>\n",
       "      <td>27</td>\n",
       "      <td>0.906487</td>\n",
       "      <td>0.915113</td>\n",
       "      <td>0.927697</td>\n",
       "      <td>0.905267</td>\n",
       "      <td>0.900315</td>\n",
       "      <td>0.910976</td>\n",
       "      <td>0.009624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.004928</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>4.586223</td>\n",
       "      <td>{'alpha': 4.586223418308644}</td>\n",
       "      <td>0.831556</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.665919</td>\n",
       "      <td>0.863666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808801</td>\n",
       "      <td>0.080939</td>\n",
       "      <td>28</td>\n",
       "      <td>0.906603</td>\n",
       "      <td>0.915247</td>\n",
       "      <td>0.927792</td>\n",
       "      <td>0.905434</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.911110</td>\n",
       "      <td>0.009603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.017177</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>4.53084</td>\n",
       "      <td>{'alpha': 4.5308397320654334}</td>\n",
       "      <td>0.831597</td>\n",
       "      <td>0.783551</td>\n",
       "      <td>0.665983</td>\n",
       "      <td>0.863463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808744</td>\n",
       "      <td>0.080871</td>\n",
       "      <td>30</td>\n",
       "      <td>0.906709</td>\n",
       "      <td>0.915369</td>\n",
       "      <td>0.927879</td>\n",
       "      <td>0.905585</td>\n",
       "      <td>0.900619</td>\n",
       "      <td>0.911232</td>\n",
       "      <td>0.009584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.017592</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>4.480959</td>\n",
       "      <td>{'alpha': 4.480958722794834}</td>\n",
       "      <td>0.831636</td>\n",
       "      <td>0.783481</td>\n",
       "      <td>0.666040</td>\n",
       "      <td>0.863277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808691</td>\n",
       "      <td>0.080810</td>\n",
       "      <td>31</td>\n",
       "      <td>0.906805</td>\n",
       "      <td>0.915480</td>\n",
       "      <td>0.927958</td>\n",
       "      <td>0.905724</td>\n",
       "      <td>0.900751</td>\n",
       "      <td>0.911344</td>\n",
       "      <td>0.009566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.018190</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>4.435987</td>\n",
       "      <td>{'alpha': 4.435987301614752}</td>\n",
       "      <td>0.831671</td>\n",
       "      <td>0.783417</td>\n",
       "      <td>0.666091</td>\n",
       "      <td>0.863108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808643</td>\n",
       "      <td>0.080754</td>\n",
       "      <td>32</td>\n",
       "      <td>0.906892</td>\n",
       "      <td>0.915581</td>\n",
       "      <td>0.928029</td>\n",
       "      <td>0.905849</td>\n",
       "      <td>0.900871</td>\n",
       "      <td>0.911445</td>\n",
       "      <td>0.009550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.017323</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>4.395404</td>\n",
       "      <td>{'alpha': 4.395404110557493}</td>\n",
       "      <td>0.831703</td>\n",
       "      <td>0.783358</td>\n",
       "      <td>0.666136</td>\n",
       "      <td>0.862954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808599</td>\n",
       "      <td>0.080703</td>\n",
       "      <td>33</td>\n",
       "      <td>0.906971</td>\n",
       "      <td>0.915673</td>\n",
       "      <td>0.928094</td>\n",
       "      <td>0.905964</td>\n",
       "      <td>0.900981</td>\n",
       "      <td>0.911537</td>\n",
       "      <td>0.009535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>4.35875</td>\n",
       "      <td>{'alpha': 4.358749576380868}</td>\n",
       "      <td>0.831733</td>\n",
       "      <td>0.783305</td>\n",
       "      <td>0.666177</td>\n",
       "      <td>0.862813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808558</td>\n",
       "      <td>0.080657</td>\n",
       "      <td>34</td>\n",
       "      <td>0.907043</td>\n",
       "      <td>0.915756</td>\n",
       "      <td>0.928153</td>\n",
       "      <td>0.906068</td>\n",
       "      <td>0.901080</td>\n",
       "      <td>0.911620</td>\n",
       "      <td>0.009522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.017354</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>4.325618</td>\n",
       "      <td>{'alpha': 4.32561754204969}</td>\n",
       "      <td>0.831760</td>\n",
       "      <td>0.783255</td>\n",
       "      <td>0.666214</td>\n",
       "      <td>0.862685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808520</td>\n",
       "      <td>0.080615</td>\n",
       "      <td>35</td>\n",
       "      <td>0.907108</td>\n",
       "      <td>0.915832</td>\n",
       "      <td>0.928207</td>\n",
       "      <td>0.906162</td>\n",
       "      <td>0.901171</td>\n",
       "      <td>0.911696</td>\n",
       "      <td>0.009510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.017701</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>4.295648</td>\n",
       "      <td>{'alpha': 4.295648195238944}</td>\n",
       "      <td>0.831785</td>\n",
       "      <td>0.783210</td>\n",
       "      <td>0.666247</td>\n",
       "      <td>0.862568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808486</td>\n",
       "      <td>0.080576</td>\n",
       "      <td>36</td>\n",
       "      <td>0.907168</td>\n",
       "      <td>0.915902</td>\n",
       "      <td>0.928256</td>\n",
       "      <td>0.906249</td>\n",
       "      <td>0.901254</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.009499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>4.268522</td>\n",
       "      <td>{'alpha': 4.268522067958857}</td>\n",
       "      <td>0.831808</td>\n",
       "      <td>0.783168</td>\n",
       "      <td>0.666277</td>\n",
       "      <td>0.862462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808455</td>\n",
       "      <td>0.080542</td>\n",
       "      <td>37</td>\n",
       "      <td>0.907221</td>\n",
       "      <td>0.915964</td>\n",
       "      <td>0.928300</td>\n",
       "      <td>0.906327</td>\n",
       "      <td>0.901329</td>\n",
       "      <td>0.911828</td>\n",
       "      <td>0.009488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.017574</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>4.243955</td>\n",
       "      <td>{'alpha': 4.243954924627399}</td>\n",
       "      <td>0.831829</td>\n",
       "      <td>0.783130</td>\n",
       "      <td>0.666304</td>\n",
       "      <td>0.862365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808426</td>\n",
       "      <td>0.080510</td>\n",
       "      <td>38</td>\n",
       "      <td>0.907271</td>\n",
       "      <td>0.916022</td>\n",
       "      <td>0.928340</td>\n",
       "      <td>0.906399</td>\n",
       "      <td>0.901397</td>\n",
       "      <td>0.911886</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.017868</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>4.221693</td>\n",
       "      <td>{'alpha': 4.221693390208238}</td>\n",
       "      <td>0.831848</td>\n",
       "      <td>0.783095</td>\n",
       "      <td>0.666328</td>\n",
       "      <td>0.862276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808400</td>\n",
       "      <td>0.080481</td>\n",
       "      <td>39</td>\n",
       "      <td>0.907315</td>\n",
       "      <td>0.916074</td>\n",
       "      <td>0.928377</td>\n",
       "      <td>0.906464</td>\n",
       "      <td>0.901460</td>\n",
       "      <td>0.911938</td>\n",
       "      <td>0.009471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.018432</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>4.201511</td>\n",
       "      <td>{'alpha': 4.20151119736483}</td>\n",
       "      <td>0.831865</td>\n",
       "      <td>0.783064</td>\n",
       "      <td>0.666350</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808375</td>\n",
       "      <td>0.080455</td>\n",
       "      <td>40</td>\n",
       "      <td>0.907356</td>\n",
       "      <td>0.916121</td>\n",
       "      <td>0.928410</td>\n",
       "      <td>0.906523</td>\n",
       "      <td>0.901517</td>\n",
       "      <td>0.911985</td>\n",
       "      <td>0.009463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>4.183206</td>\n",
       "      <td>{'alpha': 4.183205953464316}</td>\n",
       "      <td>0.831881</td>\n",
       "      <td>0.783034</td>\n",
       "      <td>0.666370</td>\n",
       "      <td>0.862122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808353</td>\n",
       "      <td>0.080431</td>\n",
       "      <td>41</td>\n",
       "      <td>0.907393</td>\n",
       "      <td>0.916165</td>\n",
       "      <td>0.928441</td>\n",
       "      <td>0.906577</td>\n",
       "      <td>0.901568</td>\n",
       "      <td>0.912029</td>\n",
       "      <td>0.009456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>4.166596</td>\n",
       "      <td>{'alpha': 4.166596345860462}</td>\n",
       "      <td>0.831896</td>\n",
       "      <td>0.783008</td>\n",
       "      <td>0.666388</td>\n",
       "      <td>0.862055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.080410</td>\n",
       "      <td>42</td>\n",
       "      <td>0.907426</td>\n",
       "      <td>0.916204</td>\n",
       "      <td>0.928468</td>\n",
       "      <td>0.906626</td>\n",
       "      <td>0.901616</td>\n",
       "      <td>0.912068</td>\n",
       "      <td>0.009450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.018625</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>4.15152</td>\n",
       "      <td>{'alpha': 4.151519718092102}</td>\n",
       "      <td>0.831909</td>\n",
       "      <td>0.782983</td>\n",
       "      <td>0.666404</td>\n",
       "      <td>0.861994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808315</td>\n",
       "      <td>0.080390</td>\n",
       "      <td>43</td>\n",
       "      <td>0.907457</td>\n",
       "      <td>0.916240</td>\n",
       "      <td>0.928493</td>\n",
       "      <td>0.906671</td>\n",
       "      <td>0.901659</td>\n",
       "      <td>0.912104</td>\n",
       "      <td>0.009444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.017708</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>4.13783</td>\n",
       "      <td>{'alpha': 4.137829961150949}</td>\n",
       "      <td>0.831921</td>\n",
       "      <td>0.782961</td>\n",
       "      <td>0.666419</td>\n",
       "      <td>0.861939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808298</td>\n",
       "      <td>0.080372</td>\n",
       "      <td>44</td>\n",
       "      <td>0.907485</td>\n",
       "      <td>0.916273</td>\n",
       "      <td>0.928516</td>\n",
       "      <td>0.906712</td>\n",
       "      <td>0.901698</td>\n",
       "      <td>0.912137</td>\n",
       "      <td>0.009439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.018642</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>4.125396</td>\n",
       "      <td>{'alpha': 4.125395673346094}</td>\n",
       "      <td>0.831932</td>\n",
       "      <td>0.782941</td>\n",
       "      <td>0.666432</td>\n",
       "      <td>0.861888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808283</td>\n",
       "      <td>0.080356</td>\n",
       "      <td>45</td>\n",
       "      <td>0.907510</td>\n",
       "      <td>0.916302</td>\n",
       "      <td>0.928537</td>\n",
       "      <td>0.906749</td>\n",
       "      <td>0.901733</td>\n",
       "      <td>0.912166</td>\n",
       "      <td>0.009434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>4.114099</td>\n",
       "      <td>{'alpha': 4.114098549949752}</td>\n",
       "      <td>0.831942</td>\n",
       "      <td>0.782922</td>\n",
       "      <td>0.666444</td>\n",
       "      <td>0.861842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808269</td>\n",
       "      <td>0.080341</td>\n",
       "      <td>46</td>\n",
       "      <td>0.907533</td>\n",
       "      <td>0.916330</td>\n",
       "      <td>0.928556</td>\n",
       "      <td>0.906782</td>\n",
       "      <td>0.901766</td>\n",
       "      <td>0.912193</td>\n",
       "      <td>0.009429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>4.103832</td>\n",
       "      <td>{'alpha': 4.103831970087253}</td>\n",
       "      <td>0.831952</td>\n",
       "      <td>0.782905</td>\n",
       "      <td>0.666455</td>\n",
       "      <td>0.861800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>0.080327</td>\n",
       "      <td>47</td>\n",
       "      <td>0.907554</td>\n",
       "      <td>0.916354</td>\n",
       "      <td>0.928573</td>\n",
       "      <td>0.906813</td>\n",
       "      <td>0.901795</td>\n",
       "      <td>0.912218</td>\n",
       "      <td>0.009425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>4.0945</td>\n",
       "      <td>{'alpha': 4.0944997535004735}</td>\n",
       "      <td>0.831960</td>\n",
       "      <td>0.782890</td>\n",
       "      <td>0.666465</td>\n",
       "      <td>0.861762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808244</td>\n",
       "      <td>0.080315</td>\n",
       "      <td>48</td>\n",
       "      <td>0.907573</td>\n",
       "      <td>0.916377</td>\n",
       "      <td>0.928589</td>\n",
       "      <td>0.906841</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.912241</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>4.086015</td>\n",
       "      <td>{'alpha': 4.086015064079849}</td>\n",
       "      <td>0.831968</td>\n",
       "      <td>0.782876</td>\n",
       "      <td>0.666474</td>\n",
       "      <td>0.861727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808233</td>\n",
       "      <td>0.080304</td>\n",
       "      <td>49</td>\n",
       "      <td>0.907591</td>\n",
       "      <td>0.916397</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.906867</td>\n",
       "      <td>0.901847</td>\n",
       "      <td>0.912261</td>\n",
       "      <td>0.009419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.017550</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>4.078299</td>\n",
       "      <td>{'alpha': 4.07829944059471}</td>\n",
       "      <td>0.831975</td>\n",
       "      <td>0.782863</td>\n",
       "      <td>0.666482</td>\n",
       "      <td>0.861695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808224</td>\n",
       "      <td>0.080293</td>\n",
       "      <td>50</td>\n",
       "      <td>0.907607</td>\n",
       "      <td>0.916416</td>\n",
       "      <td>0.928616</td>\n",
       "      <td>0.906890</td>\n",
       "      <td>0.901869</td>\n",
       "      <td>0.912280</td>\n",
       "      <td>0.009415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.017303</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>4.071282</td>\n",
       "      <td>{'alpha': 4.0712819379901255}</td>\n",
       "      <td>0.831981</td>\n",
       "      <td>0.782851</td>\n",
       "      <td>0.666490</td>\n",
       "      <td>0.861666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808215</td>\n",
       "      <td>0.080284</td>\n",
       "      <td>51</td>\n",
       "      <td>0.907621</td>\n",
       "      <td>0.916433</td>\n",
       "      <td>0.928628</td>\n",
       "      <td>0.906911</td>\n",
       "      <td>0.901889</td>\n",
       "      <td>0.912297</td>\n",
       "      <td>0.009413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.017470</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>4.064898</td>\n",
       "      <td>{'alpha': 4.064898365069302}</td>\n",
       "      <td>0.831987</td>\n",
       "      <td>0.782841</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0.861639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808207</td>\n",
       "      <td>0.080276</td>\n",
       "      <td>52</td>\n",
       "      <td>0.907634</td>\n",
       "      <td>0.916448</td>\n",
       "      <td>0.928639</td>\n",
       "      <td>0.906931</td>\n",
       "      <td>0.901908</td>\n",
       "      <td>0.912312</td>\n",
       "      <td>0.009410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "43       0.017279      0.000159         0.005047        0.000112   76.153722   \n",
       "44       0.017092      0.000174         0.004978        0.000097   58.615467   \n",
       "45       0.017417      0.000380         0.004999        0.000200   46.177695   \n",
       "46       0.017440      0.000295         0.005099        0.000288   37.158145   \n",
       "47       0.017602      0.000400         0.004979        0.000115   30.483168   \n",
       "48       0.017218      0.000537         0.004946        0.000112   25.451046   \n",
       "49       0.017627      0.000380         0.004949        0.000155    21.59295   \n",
       "50       0.017296      0.000485         0.005195        0.000399   18.589201   \n",
       "51       0.017238      0.000559         0.004914        0.000138    16.21767   \n",
       "52       0.017360      0.000272         0.005016        0.000205   14.321278   \n",
       "53       0.017155      0.000531         0.005103        0.000430   12.787124   \n",
       "54       0.018189      0.001622         0.004927        0.000086   11.532822   \n",
       "55       0.017579      0.000548         0.005249        0.000353   10.497394   \n",
       "56       0.017541      0.000535         0.005096        0.000106    9.635112   \n",
       "57       0.017654      0.000640         0.004916        0.000027    8.911258   \n",
       "58       0.017363      0.000414         0.005039        0.000151    8.299165   \n",
       "59       0.017249      0.000267         0.004860        0.000037    7.778131   \n",
       "60       0.017412      0.000303         0.006171        0.001566     7.33192   \n",
       "61       0.017582      0.000318         0.004847        0.000027    6.947675   \n",
       "62       0.017439      0.000336         0.004999        0.000157    6.615126   \n",
       "63       0.017398      0.000443         0.005096        0.000366       6.326   \n",
       "64       0.017174      0.000199         0.004828        0.000018    6.073575   \n",
       "65       0.017528      0.000230         0.004927        0.000139    5.852356   \n",
       "66       0.017403      0.000327         0.004905        0.000126    5.657812   \n",
       "67       0.017573      0.000308         0.005116        0.000219    5.486187   \n",
       "68       0.017609      0.000617         0.004953        0.000076    5.334347   \n",
       "69       0.017154      0.000105         0.005182        0.000450    5.199657   \n",
       "70       0.017306      0.000354         0.004983        0.000115    5.079896   \n",
       "71       0.018009      0.001384         0.004851        0.000022    4.973178   \n",
       "72       0.018240      0.001728         0.005740        0.001328    4.877893   \n",
       "73       0.017395      0.000398         0.005234        0.000690    4.792664   \n",
       "74       0.018663      0.001705         0.004984        0.000171    4.716303   \n",
       "75       0.018114      0.001420         0.005609        0.001546    4.647786   \n",
       "76       0.017629      0.000228         0.004928        0.000098    4.586223   \n",
       "77       0.017177      0.000405         0.004961        0.000162     4.53084   \n",
       "78       0.017592      0.000530         0.005786        0.001768    4.480959   \n",
       "79       0.018190      0.002305         0.005849        0.001893    4.435987   \n",
       "80       0.017323      0.000478         0.005518        0.001287    4.395404   \n",
       "81       0.017295      0.000214         0.006742        0.002008     4.35875   \n",
       "82       0.017354      0.000184         0.004982        0.000219    4.325618   \n",
       "83       0.017701      0.000339         0.004961        0.000122    4.295648   \n",
       "84       0.018153      0.001772         0.005066        0.000437    4.268522   \n",
       "85       0.017574      0.000406         0.005257        0.000335    4.243955   \n",
       "86       0.017868      0.001062         0.005159        0.000484    4.221693   \n",
       "87       0.018432      0.001605         0.004990        0.000124    4.201511   \n",
       "88       0.017400      0.000186         0.004846        0.000060    4.183206   \n",
       "89       0.017305      0.000214         0.004987        0.000107    4.166596   \n",
       "90       0.018625      0.002237         0.005704        0.001498     4.15152   \n",
       "91       0.017708      0.000884         0.005249        0.000706     4.13783   \n",
       "92       0.018642      0.002410         0.005132        0.000385    4.125396   \n",
       "93       0.017193      0.000147         0.004941        0.000111    4.114099   \n",
       "94       0.017509      0.000418         0.005124        0.000407    4.103832   \n",
       "95       0.018106      0.001577         0.006563        0.002150      4.0945   \n",
       "96       0.017173      0.000359         0.004889        0.000143    4.086015   \n",
       "97       0.017550      0.000457         0.005973        0.001926    4.078299   \n",
       "98       0.017303      0.000306         0.004881        0.000101    4.071282   \n",
       "99       0.017470      0.000323         0.004871        0.000097    4.064898   \n",
       "\n",
       "                           params  split0_test_score  split1_test_score  \\\n",
       "43   {'alpha': 76.15372213775619}           0.813546           0.774176   \n",
       "44   {'alpha': 58.61546721719499}           0.816721           0.777533   \n",
       "45  {'alpha': 46.177694642348854}           0.819333           0.780149   \n",
       "46  {'alpha': 37.158144933965566}           0.821452           0.782151   \n",
       "47  {'alpha': 30.483168194087035}           0.823155           0.783654   \n",
       "48  {'alpha': 25.451046439053968}           0.824517           0.784756   \n",
       "49  {'alpha': 21.592949974044902}           0.825606           0.785544   \n",
       "50   {'alpha': 18.58920129397054}           0.826480           0.786086   \n",
       "51  {'alpha': 16.217669865086737}           0.827185           0.786436   \n",
       "52  {'alpha': 14.321277703921314}           0.827760           0.786638   \n",
       "53   {'alpha': 12.78712416946227}           0.828235           0.786726   \n",
       "54   {'alpha': 11.53282176451345}           0.828632           0.786729   \n",
       "55   {'alpha': 10.49739405886303}           0.828968           0.786667   \n",
       "56   {'alpha': 9.635112378383278}           0.829257           0.786559   \n",
       "57   {'alpha': 8.911257834966829}           0.829509           0.786416   \n",
       "58   {'alpha': 8.299164947833209}           0.829730           0.786251   \n",
       "59    {'alpha': 7.77813118894308}           0.829927           0.786072   \n",
       "60   {'alpha': 7.331919888627737}           0.830104           0.785884   \n",
       "61    {'alpha': 6.94767515680434}           0.830264           0.785694   \n",
       "62    {'alpha': 6.61512649821009}           0.830409           0.785505   \n",
       "63   {'alpha': 6.325999535037175}           0.830542           0.785319   \n",
       "64  {'alpha': 6.0735750137322295}           0.830664           0.785139   \n",
       "65   {'alpha': 5.852355627412319}           0.830776           0.784966   \n",
       "66   {'alpha': 5.657812017433985}           0.830879           0.784801   \n",
       "67     {'alpha': 5.4861874773066}           0.830974           0.784644   \n",
       "68   {'alpha': 5.334346570692043}           0.831062           0.784497   \n",
       "69   {'alpha': 5.199656882240699}           0.831142           0.784359   \n",
       "70   {'alpha': 5.079895970452175}           0.831217           0.784230   \n",
       "71   {'alpha': 4.973177638541748}           0.831285           0.784109   \n",
       "72   {'alpha': 4.877893122210622}           0.831349           0.783997   \n",
       "73   {'alpha': 4.792663876801774}           0.831407           0.783893   \n",
       "74    {'alpha': 4.71630344457983}           0.831461           0.783797   \n",
       "75   {'alpha': 4.647786475524222}           0.831510           0.783708   \n",
       "76   {'alpha': 4.586223418308644}           0.831556           0.783626   \n",
       "77  {'alpha': 4.5308397320654334}           0.831597           0.783551   \n",
       "78   {'alpha': 4.480958722794834}           0.831636           0.783481   \n",
       "79   {'alpha': 4.435987301614752}           0.831671           0.783417   \n",
       "80   {'alpha': 4.395404110557493}           0.831703           0.783358   \n",
       "81   {'alpha': 4.358749576380868}           0.831733           0.783305   \n",
       "82    {'alpha': 4.32561754204969}           0.831760           0.783255   \n",
       "83   {'alpha': 4.295648195238944}           0.831785           0.783210   \n",
       "84   {'alpha': 4.268522067958857}           0.831808           0.783168   \n",
       "85   {'alpha': 4.243954924627399}           0.831829           0.783130   \n",
       "86   {'alpha': 4.221693390208238}           0.831848           0.783095   \n",
       "87    {'alpha': 4.20151119736483}           0.831865           0.783064   \n",
       "88   {'alpha': 4.183205953464316}           0.831881           0.783034   \n",
       "89   {'alpha': 4.166596345860462}           0.831896           0.783008   \n",
       "90   {'alpha': 4.151519718092102}           0.831909           0.782983   \n",
       "91   {'alpha': 4.137829961150949}           0.831921           0.782961   \n",
       "92   {'alpha': 4.125395673346094}           0.831932           0.782941   \n",
       "93   {'alpha': 4.114098549949752}           0.831942           0.782922   \n",
       "94   {'alpha': 4.103831970087253}           0.831952           0.782905   \n",
       "95  {'alpha': 4.0944997535004735}           0.831960           0.782890   \n",
       "96   {'alpha': 4.086015064079849}           0.831968           0.782876   \n",
       "97    {'alpha': 4.07829944059471}           0.831975           0.782863   \n",
       "98  {'alpha': 4.0712819379901255}           0.831981           0.782851   \n",
       "99   {'alpha': 4.064898365069302}           0.831987           0.782841   \n",
       "\n",
       "    split2_test_score  split3_test_score  ...  mean_test_score  \\\n",
       "43           0.619143           0.892927  ...         0.799416   \n",
       "44           0.625413           0.892498  ...         0.802250   \n",
       "45           0.630973           0.891648  ...         0.804526   \n",
       "46           0.635860           0.890484  ...         0.806325   \n",
       "47           0.640122           0.889098  ...         0.807720   \n",
       "48           0.643814           0.887570  ...         0.808778   \n",
       "49           0.646996           0.885966  ...         0.809563   \n",
       "50           0.649728           0.884337  ...         0.810127   \n",
       "51           0.652067           0.882721  ...         0.810515   \n",
       "52           0.654067           0.881148  ...         0.810765   \n",
       "53           0.655775           0.879636  ...         0.810907   \n",
       "54           0.657233           0.878200  ...         0.810966   \n",
       "55           0.658478           0.876847  ...         0.810964   \n",
       "56           0.659542           0.875579  ...         0.810915   \n",
       "57           0.660453           0.874398  ...         0.810833   \n",
       "58           0.661233           0.873303  ...         0.810727   \n",
       "59           0.661903           0.872290  ...         0.810606   \n",
       "60           0.662479           0.871356  ...         0.810475   \n",
       "61           0.662975           0.870497  ...         0.810339   \n",
       "62           0.663404           0.869708  ...         0.810202   \n",
       "63           0.663775           0.868983  ...         0.810066   \n",
       "64           0.664098           0.868320  ...         0.809934   \n",
       "65           0.664379           0.867712  ...         0.809806   \n",
       "66           0.664623           0.867156  ...         0.809683   \n",
       "67           0.664838           0.866648  ...         0.809567   \n",
       "68           0.665026           0.866184  ...         0.809456   \n",
       "69           0.665191           0.865760  ...         0.809353   \n",
       "70           0.665336           0.865373  ...         0.809256   \n",
       "71           0.665465           0.865019  ...         0.809165   \n",
       "72           0.665578           0.864697  ...         0.809081   \n",
       "73           0.665679           0.864403  ...         0.809003   \n",
       "74           0.665769           0.864134  ...         0.808930   \n",
       "75           0.665848           0.863890  ...         0.808863   \n",
       "76           0.665919           0.863666  ...         0.808801   \n",
       "77           0.665983           0.863463  ...         0.808744   \n",
       "78           0.666040           0.863277  ...         0.808691   \n",
       "79           0.666091           0.863108  ...         0.808643   \n",
       "80           0.666136           0.862954  ...         0.808599   \n",
       "81           0.666177           0.862813  ...         0.808558   \n",
       "82           0.666214           0.862685  ...         0.808520   \n",
       "83           0.666247           0.862568  ...         0.808486   \n",
       "84           0.666277           0.862462  ...         0.808455   \n",
       "85           0.666304           0.862365  ...         0.808426   \n",
       "86           0.666328           0.862276  ...         0.808400   \n",
       "87           0.666350           0.862196  ...         0.808375   \n",
       "88           0.666370           0.862122  ...         0.808353   \n",
       "89           0.666388           0.862055  ...         0.808333   \n",
       "90           0.666404           0.861994  ...         0.808315   \n",
       "91           0.666419           0.861939  ...         0.808298   \n",
       "92           0.666432           0.861888  ...         0.808283   \n",
       "93           0.666444           0.861842  ...         0.808269   \n",
       "94           0.666455           0.861800  ...         0.808256   \n",
       "95           0.666465           0.861762  ...         0.808244   \n",
       "96           0.666474           0.861727  ...         0.808233   \n",
       "97           0.666482           0.861695  ...         0.808224   \n",
       "98           0.666490           0.861666  ...         0.808215   \n",
       "99           0.666497           0.861639  ...         0.808207   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "43        0.101645               57            0.863607            0.873146   \n",
       "44        0.099612               56            0.869307            0.878476   \n",
       "45        0.097715               55            0.874259            0.883120   \n",
       "46        0.095965               54            0.878533            0.887142   \n",
       "47        0.094367               53            0.882209            0.890617   \n",
       "48        0.092917               29            0.885366            0.893617   \n",
       "49        0.091610               19            0.888077            0.896213   \n",
       "50        0.090436               13            0.890410            0.898464   \n",
       "51        0.089384                9            0.892423            0.900423   \n",
       "52        0.088443                6            0.894164            0.902136   \n",
       "53        0.087602                4            0.895676            0.903639   \n",
       "54        0.086852                1            0.896993            0.904962   \n",
       "55        0.086182                2            0.898145            0.906132   \n",
       "56        0.085583                3            0.899157            0.907169   \n",
       "57        0.085048                5            0.900047            0.908092   \n",
       "58        0.084570                7            0.900834            0.908916   \n",
       "59        0.084142                8            0.901532            0.909652   \n",
       "60        0.083759               10            0.902151            0.910312   \n",
       "61        0.083415               11            0.902703            0.910905   \n",
       "62        0.083106               12            0.903196            0.911438   \n",
       "63        0.082829               14            0.903637            0.911919   \n",
       "64        0.082579               15            0.904032            0.912353   \n",
       "65        0.082354               16            0.904387            0.912744   \n",
       "66        0.082152               17            0.904706            0.913099   \n",
       "67        0.081969               18            0.904993            0.913419   \n",
       "68        0.081804               20            0.905252            0.913710   \n",
       "69        0.081655               21            0.905486            0.913973   \n",
       "70        0.081520               22            0.905697            0.914212   \n",
       "71        0.081398               23            0.905888            0.914428   \n",
       "72        0.081287               24            0.906061            0.914625   \n",
       "73        0.081187               25            0.906217            0.914804   \n",
       "74        0.081096               26            0.906359            0.914966   \n",
       "75        0.081014               27            0.906487            0.915113   \n",
       "76        0.080939               28            0.906603            0.915247   \n",
       "77        0.080871               30            0.906709            0.915369   \n",
       "78        0.080810               31            0.906805            0.915480   \n",
       "79        0.080754               32            0.906892            0.915581   \n",
       "80        0.080703               33            0.906971            0.915673   \n",
       "81        0.080657               34            0.907043            0.915756   \n",
       "82        0.080615               35            0.907108            0.915832   \n",
       "83        0.080576               36            0.907168            0.915902   \n",
       "84        0.080542               37            0.907221            0.915964   \n",
       "85        0.080510               38            0.907271            0.916022   \n",
       "86        0.080481               39            0.907315            0.916074   \n",
       "87        0.080455               40            0.907356            0.916121   \n",
       "88        0.080431               41            0.907393            0.916165   \n",
       "89        0.080410               42            0.907426            0.916204   \n",
       "90        0.080390               43            0.907457            0.916240   \n",
       "91        0.080372               44            0.907485            0.916273   \n",
       "92        0.080356               45            0.907510            0.916302   \n",
       "93        0.080341               46            0.907533            0.916330   \n",
       "94        0.080327               47            0.907554            0.916354   \n",
       "95        0.080315               48            0.907573            0.916377   \n",
       "96        0.080304               49            0.907591            0.916397   \n",
       "97        0.080293               50            0.907607            0.916416   \n",
       "98        0.080284               51            0.907621            0.916433   \n",
       "99        0.080276               52            0.907634            0.916448   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "43            0.896373            0.854380            0.853782   \n",
       "44            0.900178            0.860653            0.859520   \n",
       "45            0.903542            0.866153            0.864521   \n",
       "46            0.906501            0.870951            0.868866   \n",
       "47            0.909094            0.875126            0.872638   \n",
       "48            0.911360            0.878756            0.875915   \n",
       "49            0.913338            0.881914            0.878768   \n",
       "50            0.915065            0.884667            0.881259   \n",
       "51            0.916574            0.887073            0.883441   \n",
       "52            0.917896            0.889182            0.885360   \n",
       "53            0.919056            0.891036            0.887052   \n",
       "54            0.920076            0.892672            0.888549   \n",
       "55            0.920976            0.894119            0.889879   \n",
       "56            0.921772            0.895404            0.891064   \n",
       "57            0.922478            0.896547            0.892121   \n",
       "58            0.923105            0.897568            0.893068   \n",
       "59            0.923664            0.898481            0.893918   \n",
       "60            0.924162            0.899300            0.894682   \n",
       "61            0.924608            0.900036            0.895370   \n",
       "62            0.925007            0.900698            0.895991   \n",
       "63            0.925365            0.901295            0.896552   \n",
       "64            0.925687            0.901833            0.897059   \n",
       "65            0.925976            0.902320            0.897518   \n",
       "66            0.926237            0.902760            0.897934   \n",
       "67            0.926472            0.903159            0.898311   \n",
       "68            0.926684            0.903520            0.898653   \n",
       "69            0.926875            0.903847            0.898963   \n",
       "70            0.927049            0.904144            0.899246   \n",
       "71            0.927205            0.904414            0.899502   \n",
       "72            0.927347            0.904659            0.899735   \n",
       "73            0.927475            0.904881            0.899947   \n",
       "74            0.927591            0.905083            0.900139   \n",
       "75            0.927697            0.905267            0.900315   \n",
       "76            0.927792            0.905434            0.900474   \n",
       "77            0.927879            0.905585            0.900619   \n",
       "78            0.927958            0.905724            0.900751   \n",
       "79            0.928029            0.905849            0.900871   \n",
       "80            0.928094            0.905964            0.900981   \n",
       "81            0.928153            0.906068            0.901080   \n",
       "82            0.928207            0.906162            0.901171   \n",
       "83            0.928256            0.906249            0.901254   \n",
       "84            0.928300            0.906327            0.901329   \n",
       "85            0.928340            0.906399            0.901397   \n",
       "86            0.928377            0.906464            0.901460   \n",
       "87            0.928410            0.906523            0.901517   \n",
       "88            0.928441            0.906577            0.901568   \n",
       "89            0.928468            0.906626            0.901616   \n",
       "90            0.928493            0.906671            0.901659   \n",
       "91            0.928516            0.906712            0.901698   \n",
       "92            0.928537            0.906749            0.901733   \n",
       "93            0.928556            0.906782            0.901766   \n",
       "94            0.928573            0.906813            0.901795   \n",
       "95            0.928589            0.906841            0.901822   \n",
       "96            0.928603            0.906867            0.901847   \n",
       "97            0.928616            0.906890            0.901869   \n",
       "98            0.928628            0.906911            0.901889   \n",
       "99            0.928639            0.906931            0.901908   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "43          0.868258         0.015736  \n",
       "44          0.873627         0.014930  \n",
       "45          0.878319         0.014242  \n",
       "46          0.882399         0.013657  \n",
       "47          0.885937         0.013159  \n",
       "48          0.889003         0.012733  \n",
       "49          0.891662         0.012367  \n",
       "50          0.893973         0.012050  \n",
       "51          0.895987         0.011773  \n",
       "52          0.897748         0.011532  \n",
       "53          0.899292         0.011319  \n",
       "54          0.900651         0.011130  \n",
       "55          0.901850         0.010963  \n",
       "56          0.902913         0.010814  \n",
       "57          0.903857         0.010680  \n",
       "58          0.904698         0.010561  \n",
       "59          0.905449         0.010453  \n",
       "60          0.906122         0.010356  \n",
       "61          0.906724         0.010268  \n",
       "62          0.907266         0.010188  \n",
       "63          0.907753         0.010116  \n",
       "64          0.908193         0.010051  \n",
       "65          0.908589         0.009991  \n",
       "66          0.908947         0.009937  \n",
       "67          0.909271         0.009888  \n",
       "68          0.909564         0.009843  \n",
       "69          0.909829         0.009803  \n",
       "70          0.910069         0.009766  \n",
       "71          0.910287         0.009732  \n",
       "72          0.910485         0.009701  \n",
       "73          0.910665         0.009673  \n",
       "74          0.910828         0.009647  \n",
       "75          0.910976         0.009624  \n",
       "76          0.911110         0.009603  \n",
       "77          0.911232         0.009584  \n",
       "78          0.911344         0.009566  \n",
       "79          0.911445         0.009550  \n",
       "80          0.911537         0.009535  \n",
       "81          0.911620         0.009522  \n",
       "82          0.911696         0.009510  \n",
       "83          0.911765         0.009499  \n",
       "84          0.911828         0.009488  \n",
       "85          0.911886         0.009479  \n",
       "86          0.911938         0.009471  \n",
       "87          0.911985         0.009463  \n",
       "88          0.912029         0.009456  \n",
       "89          0.912068         0.009450  \n",
       "90          0.912104         0.009444  \n",
       "91          0.912137         0.009439  \n",
       "92          0.912166         0.009434  \n",
       "93          0.912193         0.009429  \n",
       "94          0.912218         0.009425  \n",
       "95          0.912241         0.009422  \n",
       "96          0.912261         0.009419  \n",
       "97          0.912280         0.009415  \n",
       "98          0.912297         0.009413  \n",
       "99          0.912312         0.009410  \n",
       "\n",
       "[57 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_ridge.cv_results_)\n",
    "cv_results = cv_results[cv_results['param_alpha']<=100]\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3921db42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting mean test and train scoes with alpha \n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "# plotting\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Score')\n",
    "plt.title(\"Model score with respect to alpha \")\n",
    "plt.legend(['train score', 'test score'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1dd7335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Ridge(alpha=11.050251256281406, random_state=42)\n",
      "0.8109719476264365\n"
     ]
    }
   ],
   "source": [
    "# It seems like the score function seems to be a smooth function with respect to the alpha hyperparameter. \n",
    "# Let us get closer to the global max score by varying the alpha around the value that we found above\n",
    "\n",
    "\n",
    "params_grid_max= {'alpha': np.linspace(10.5,12.0,200)}\n",
    "\n",
    "grid_ridge_max= GridSearchCV(estimator= ridge, \n",
    "                        param_grid= params_grid_max,\n",
    "                        cv= 5,\n",
    "                        scoring= 'r2',\n",
    "                        return_train_score= True,\n",
    "                        verbose= 1)      \n",
    "grid_ridge_max.fit(X_train, y_train)\n",
    "\n",
    "print(grid_ridge_max.best_estimator_)\n",
    "print(grid_ridge_max.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c90f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 24989.5643275489\n",
      "Root Mean Squared Error: 30778.33909959441\n"
     ]
    }
   ],
   "source": [
    "# Last we print the values of standard error \n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train,grid_ridge_max.predict(X_train)))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test,grid_ridge_max.predict(X_test)))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04230fdf",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e4c18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RandomForest_pipe = make_pipeline(\n",
    "    RandomForestRegressor(random_state=47)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da64d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "\n",
    "RandomForest_cv_results = cross_validate(RandomForest_pipe, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ddf2599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86644714, 0.76989342, 0.81038733, 0.88082563, 0.87552775])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_cv_scores = RandomForest_cv_results['test_score']\n",
    "RandomForest_cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5c74e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8406162536779729, 0.04340126316420154)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(RandomForest_cv_scores), np.std(RandomForest_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "faa1820a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__n_estimators': [10,\n",
       "  12,\n",
       "  16,\n",
       "  20,\n",
       "  26,\n",
       "  33,\n",
       "  42,\n",
       "  54,\n",
       "  69,\n",
       "  88,\n",
       "  112,\n",
       "  143,\n",
       "  183,\n",
       "  233,\n",
       "  297,\n",
       "  379,\n",
       "  483,\n",
       "  615,\n",
       "  784,\n",
       "  1000]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter search using GridSearchCV\n",
    "\n",
    "n_est = [int(n) for n in np.logspace(start=1, stop=3, num=20)]\n",
    "grid_params = {\n",
    "        'randomforestregressor__n_estimators': n_est\n",
    "}\n",
    "grid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "215dba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_grid_cv = GridSearchCV(RandomForest_pipe, param_grid=grid_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ec38705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('randomforestregressor',\n",
       "                                        RandomForestRegressor(random_state=47))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'randomforestregressor__n_estimators': [10, 12, 16, 20,\n",
       "                                                                 26, 33, 42, 54,\n",
       "                                                                 69, 88, 112,\n",
       "                                                                 143, 183, 233,\n",
       "                                                                 297, 379, 483,\n",
       "                                                                 615, 784,\n",
       "                                                                 1000]})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91efb27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__n_estimators': 112}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0ebee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86850254, 0.77325839, 0.80840105, 0.88036394, 0.87576807])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest_best_cv_results = cross_validate(RandomForest_grid_cv.best_estimator_, X_train, y_train, cv=5)\n",
    "RandomForest_best_scores = RandomForest_best_cv_results['test_score']\n",
    "RandomForest_best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ee59a39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8412587989613494, 0.042815907639492654)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(RandomForest_best_scores), np.std(RandomForest_best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d83e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 11676.835396743787\n",
      "Root Mean Squared Error: 29496.25289313527\n"
     ]
    }
   ],
   "source": [
    "# Last we print the values of standard error \n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_train,RandomForest_grid_cv.predict(X_train)))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test,RandomForest_grid_cv.predict(X_test)))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that the Random Forest performs the best among all the models that we discussed in here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
